---
title: "Using machine learning to predict/classify species of beetles"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE) #defines default echo (display code)
knitr::opts_chunk$set(eval = TRUE) #defines default eval (display result of code)
knitr::opts_chunk$set(comment = "") # no space/character before results (e.g. in tables)
knitr::opts_chunk$set(tidy = T) # let r reformat your code to look tidy in the output
knitr::opts_chunk$set(collapse = F) # should code and results be shown in the same chunk (=T) or be split in several chunks in the document (=F)
```

```{r libraries, include=F}

library(tidyverse)
library(dplyr)
library(randomForest)
library(ggplot2)
library(readxl)
library(mice)
library(corrr)
library(ggcorrplot)
library(caret)

```

```{r load data, include=F}
# Load the data
beetle_data <- read_xlsx("morphometrics_v2.xlsx", col_names = T, na = "NA") 
```

## Data
Explanation of variables in the data:

* **ID**: ID of the beetle specimen.

* **morphotype**: The species of beetle. All within the genus Hydrobius. This is the outcome I want to predict.

* **15 morphological features**: Includes body size, length and width of the wings and pronotum, and smaller structures on the males. Most measured in mm or Î¼m. Some features are ratios between two lengths. One feature characterizing the shape of a structure (mesoShape) is an angle that is measured in degrees. See publication for details. 


Looking at the number of samples per species.
```{r sample sizes}
table(beetle_data$morphotype)
```

Next, looking at how much missing data there is per variable:
```{r missingness}
# Missing per variables
naniar::vis_miss(beetle_data)

# Number of specimens with complete data
table(beetle_data[complete.cases(beetle_data),"morphotype" ])
```

As seen, there are very few complete cases, primarily do high missingness in variables that were difficult/time-consuming to measure. Not ideal, but can imputation to fill in likely missing values. 

## Split data into train and test set
Before doing any imputation, need to split the data into train and test data. That way data leakage will be avoided. 

Want to split the data to have 60% train and 40% test data. Using stratified splitting with species as the strata. Note that multiple splits could be done to test the effect of the split, but not done here. Bootstrapping methods for validation are also options later instead of using data-split method. Since the data is highly informative, want to also do a 25% train - 75% test set to really see if possible to get a good model with very little data. 
```{r data split}
#set the seed for reproducibility
set.seed(200)

# Get train index: y is the outcome variable to stratify with, p is the proportion in test
trainIndex_60_40 <- createDataPartition(beetle_data$morphotype, 
                                  p = .60, 
                                  list = FALSE, 
                                  times = 1)

trainIndex_25_75 <- createDataPartition(beetle_data$morphotype, 
                                  p = .25, 
                                  list = FALSE, 
                                  times = 1)

# Split the data in 2:
beetle_train_60_40 <- beetle_data[trainIndex_60_40, ]
beetle_test_60_40 <- beetle_data[-trainIndex_60_40, ]

beetle_train_25_75 <- beetle_data[trainIndex_25_75, ]
beetle_test_25_75 <- beetle_data[-trainIndex_25_75, ]

```

Check the distribution of species per dataset.
```{r split sample sizes}
#Train
table(beetle_train_60_40$morphotype)
table(beetle_train_25_75$morphotype)

#Test
table(beetle_test_60_40$morphotype)
table(beetle_test_25_75$morphotype)

```

## Imputation of missing data
In an ideal world I would want to use Multiple Imputation by Chained Equations (MICE) to get reasonable imputed datapoints. However, due to how the data is missing it is not possible to do this perfectly. First, MICE assumes linear relationships and no interactions between variables that will be imputed. We likely have both of these here, and even clear interactions between predictors and the outcome/species (i.e. 2-way interaction between (outcome x predictor Z) on predictor Y). Meaning that the effect of predictor Z on predictor Y will depend on the species. MICE treats the effect as being the same for all, i.e. no interaction, and would severely reduce the correlations between species and predictors. Secondly, key variables have high missing percentages. 

The best option to handle the interactions, is to do the imputation within each species. While this will give good imputations overall, it uses information (the species identity) that would be unknown in real new data. As such, it implies that we would need to make sure to collect key variables for any new individual, as the validation is only valid for individuals with low missingness. Since this is a toy example, accept this limitation and for simplicity, only doing one imputed dataset, although ideally you want to do several. In some cases one variable was entirely co-linear with others and MICE didn't impute those. Instead the mean value of the species was used as the imputation. 

To reduce data leakage, imputation was done on train data, and the train data imputation rules were then used to impute the test data. 
```{r mice, results='hide'}
# Imputation with the following parameters
## data[,-1] to exclude the ID in the imputation
## m = 1 means that only one imputed dataset is used
## maxit = 25 means that 25 iterations were performed
## ignore = a vector with FALSE for train data and TRUE for test data. If true, data is imputed but not used to find the imputation rules. If false, data is used for finding the rule and is imputed.

## Combine train and test data for downstream imputation
beetle_df_combined_60_40 <- rbind( 
  beetle_train_60_40 %>% mutate(data_type = "train"),
  beetle_test_60_40%>% mutate(data_type = "test")
  ) #combine data into one df

beetle_df_combined_25_75 <- rbind( 
  beetle_train_25_75 %>% mutate(data_type = "train"),
  beetle_test_25_75 %>% mutate(data_type = "test")
  ) #combine data into one df

## Arcticus
arc_df_combined_60_40 <- beetle_df_combined_60_40[,-1] %>% filter(morphotype=="arcticus")
imp_arc_60_40 <- mice(data = arc_df_combined_60_40, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(arc_df_combined_60_40$data_type=="train")), 
                               rep(TRUE, sum(arc_df_combined_60_40$data_type=="test"))))  # run imputation
arc_df_60_40 <- complete(imp_arc_60_40) # store imputed values
sum(is.na(arc_df_60_40)) # no NAs

arc_df_combined_25_75 <- beetle_df_combined_25_75[,-1] %>% filter(morphotype=="arcticus")
imp_arc_25_75 <- mice(data = arc_df_combined_25_75, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(arc_df_combined_25_75$data_type=="train")), 
                               rep(TRUE, sum(arc_df_combined_25_75$data_type=="test"))))  # run imputation
arc_df_25_75 <- complete(imp_arc_25_75) # store imputed values
sum(is.na(arc_df_25_75)) # no NAs


## Fuscipes
fus_df_combined_60_40 <- beetle_df_combined_60_40[,-1] %>% filter(morphotype=="fuscipes")
imp_fus_60_40 <- mice(data = fus_df_combined_60_40, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(fus_df_combined_60_40$data_type=="train")), 
                               rep(TRUE, sum(fus_df_combined_60_40$data_type=="test"))))  # run imputation
fus_df_60_40 <- complete(imp_fus_60_40) # store imputed values
sum(is.na(fus_df_60_40)) # 26 NA in posSetipunct
fus_df_60_40$posSetipunct[is.na(fus_df_60_40$posSetipunct)] <- 
  mean(fus_df_60_40$posSetipunct[fus_df_60_40$data_type=="train"],na.rm=T) # replace NA with mean of TRAIN data

fus_df_combined_25_75 <- beetle_df_combined_25_75[,-1] %>% filter(morphotype=="fuscipes")
imp_fus_25_75 <- mice(data = fus_df_combined_25_75, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(fus_df_combined_25_75$data_type=="train")), 
                               rep(TRUE, sum(fus_df_combined_25_75$data_type=="test"))))  # run imputation
fus_df_25_75 <- complete(imp_fus_25_75) # store imputed values
sum(is.na(fus_df_25_75)) # 26 NA in posSetipunct
fus_df_25_75$posSetipunct[is.na(fus_df_25_75$posSetipunct)] <- 
  mean(fus_df_25_75$posSetipunct[fus_df_25_75$data_type=="train"],na.rm=T) # replace NA with mean of TRAIN data

## Subrotundus
sub_df_combined_60_40 <- beetle_df_combined_60_40[,-1] %>% filter(morphotype=="subrotundus")
imp_sub_60_40 <- mice(data = sub_df_combined_60_40, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(sub_df_combined_60_40$data_type=="train")), 
                               rep(TRUE, sum(sub_df_combined_60_40$data_type=="test"))))  # run imputation
sub_df_60_40 <- complete(imp_sub_60_40) # store imputed values
sum(is.na(sub_df_60_40)) # no NAs

sub_df_combined_25_75 <- beetle_df_combined_25_75[,-1] %>% filter(morphotype=="subrotundus")
#imp_sub_25_75 <- mice(data = sub_df_combined_25_75, m = 1, maxit = 25, seed=101, 
#                      ignore=c(rep(FALSE, sum(sub_df_combined_25_75$data_type=="train")), 
#                               rep(TRUE, sum(sub_df_combined_25_75$data_type=="test"))))  # run imputation
## This failed due to too small N in train data. Instead, impute mean of train data everywhere
sub_train_means <- lapply(sub_df_combined_25_75[sub_df_combined_25_75$data_type=="train",], FUN = mean, na.rm=T)
for(i in unique(colnames(sub_df_combined_25_75))){
  sub_df_combined_25_75[[i]][is.na(sub_df_combined_25_75[[i]])] <- sub_train_means[[i]]
}
sum(is.na(sub_df_combined_25_75)) # no NAs
sub_df_25_75 <- sub_df_combined_25_75

## Rottenbergii
rot_df_combined_60_40 <- beetle_df_combined_60_40[,-1] %>% filter(morphotype=="rottenbergii")
imp_rot_60_40 <- mice(data = rot_df_combined_60_40, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(rot_df_combined_60_40$data_type=="train")), 
                               rep(TRUE, sum(rot_df_combined_60_40$data_type=="test"))))  # run imputation
rot_df_60_40 <- complete(imp_rot_60_40) # store imputed values
sum(is.na(rot_df_60_40)) # 19 NA in posSetipunct
rot_df_60_40$posSetipunct[is.na(rot_df_60_40$posSetipunct)] <- 
  mean(rot_df_60_40$posSetipunct[rot_df_60_40$data_type=="train"],na.rm=T) # replace NA with mean of TRAIN data

rot_df_combined_25_75 <- beetle_df_combined_25_75[,-1] %>% filter(morphotype=="rottenbergii")
imp_rot_25_75 <- mice(data = rot_df_combined_25_75, m = 1, maxit = 25, seed=101, 
                      ignore=c(rep(FALSE, sum(rot_df_combined_25_75$data_type=="train")), 
                               rep(TRUE, sum(rot_df_combined_25_75$data_type=="test"))))  # run imputation
rot_df_25_75 <- complete(imp_rot_25_75) # store imputed values
sum(is.na(rot_df_25_75)) # 26 NA in posSetipunct
rot_df_25_75$posSetipunct[is.na(rot_df_25_75$posSetipunct)] <- 
  mean(rot_df_25_75$posSetipunct[rot_df_25_75$data_type=="train"],na.rm=T) # replace NA with mean of TRAIN data

# Save the complete data including the imputations as a new dataframes
beetle_data_imp_60_40 <- rbind(arc_df_60_40,rot_df_60_40, fus_df_60_40, sub_df_60_40) #complete data 60_40 split
beetle_data_imp_25_75 <- rbind(arc_df_25_75,rot_df_25_75, fus_df_25_75, sub_df_25_75) #complete data 25_75 split

beetle_data_train_60_40 <- beetle_data_imp_60_40 %>% filter(data_type=="train") %>% select(-c(data_type))
beetle_data_train_25_75 <- beetle_data_imp_25_75 %>% filter(data_type=="train") %>% select(-c(data_type))

beetle_data_test_60_40 <- beetle_data_imp_60_40 %>% filter(data_type=="test") %>% select(-c(data_type))
beetle_data_test_25_75 <- beetle_data_imp_25_75 %>% filter(data_type=="test") %>% select(-c(data_type))

```

## Visualize the data with PCA
Start by getting the matrix with predictors and scaling the variables.
```{r matrix}
# Obtain matrix with only numeric values, no morphotype of data_Type
beetle_matrix_60_40 <- beetle_data_imp_60_40 %>% select(-c(morphotype, data_type))
beetle_matrix_25_75 <- beetle_data_imp_25_75 %>% select(-c(morphotype, data_type))

# Scale the variables
beetle_matrix_scaled_60_40 <- beetle_matrix_60_40 %>% scale(.)
beetle_matrix_scaled_25_75 <- beetle_matrix_25_75 %>% scale(.)

```

Obtain the correlation matrix and plot this.
```{r correlation}
#Obtain correlation metrix
beetle_matrix_corr_60_40 <- cor(beetle_matrix_scaled_60_40)
beetle_matrix_corr_25_75 <- cor(beetle_matrix_scaled_25_75)

# Plot correlation
ggcorrplot(beetle_matrix_corr_60_40)
ggcorrplot(beetle_matrix_corr_25_75)

```

Next, calculate the components using the correlation matrix
```{r PCA}
#Do PCA
beetle_pca_60_40 <- princomp(beetle_matrix_scaled_60_40, cor = F)
beetle_pca_25_75 <- princomp(beetle_matrix_scaled_25_75, cor = F)

# Summary of components
summary(beetle_pca_60_40)
summary(beetle_pca_25_75)

# Loadings for the first 2 components
beetle_pca_60_40$loadings[,1:2]
```

Need 7 components to explain >90% of the variance. First 2 components explain 64% of the variance.


Lastly, make the PCA plot.
```{r PCA plot}
factoextra::fviz_pca_ind(beetle_pca_60_40,
             col.ind = beetle_data_imp_60_40$morphotype, # color by groups
             geom = "point", # only show points
             addEllipses = T, 
             ellipse.type = "norm", # make the convex hull, other options are also possible
             legend.title = "Species",
             repel = TRUE
             )

factoextra::fviz_pca_ind(beetle_pca_25_75,
             col.ind = beetle_data_imp_25_75$morphotype, # color by groups
             geom = "point", # only show points
             addEllipses = T, 
             ellipse.type = "norm", # make the convex hull, other options are also possible
             legend.title = "Species",
             repel = TRUE
             )

```

## Train and test a random forest model: 60-40 split
Start by training and evaluating the 60-40 split. Doing parameter tuning for the number of randomly selected predictors in each split (mtry), while keeping number of trees constant (ntree=1000). Nodesize= 1 (i.e. need at least one individual in each split). maxnode not set, meaning the tree can grow to max size. Could also tune the number of trees, but seems ok like this for this toy example.

```{r train 60-40}
# Tuning parameters: using 10-fold cross-validation with a grid search 
train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                           number=10, # number of folds
                           search = "grid", # we are performing a "grid search" for tuning
                           )
set.seed(874)
model_rf_60_40 <- train(morphotype ~ .,
                       data = beetle_data_train_60_40,
                       method = "rf", # this will use the randomForest::randomForest function
                       metric = "Accuracy", # which metric should be optimized for 
                       trControl = train_ctrl,
                        tuneLength  = 10, # the number mtry to test, 10 different ones here
                       # options to be passed to randomForest
                       ntree = 1000,
                       nodesize=1,
                       keep.forest=TRUE,
                       importance=TRUE) 
model_rf_60_40
plot(model_rf_60_40)

```

Using 2 randomly selected predictors (mtry=2) during tree splits gives best accuracy.

Check variable importance next:
```{r varimportance train 60_40}
varImpPlot(model_rf_60_40$finalModel)
```
Nothing too surprising here.

Next, how are the performance and confusion matrix for train and test set:
```{r performance confusionmatrix 60_40}
#Train data
p_train <- predict(model_rf_60_40, beetle_data_train_60_40)
confusionMatrix(p_train, factor(beetle_data_train_60_40$morphotype))
## 100% accurate on train data

#Test data
p_test <- predict(model_rf_60_40, beetle_data_test_60_40)
confusionMatrix(p_test, factor(beetle_data_test_60_40$morphotype))
## 1 wrong subrotundus, else all correct
```

Visualize the performance/predictions
```{r 60_40 plots}
#Obtain probabilities and predicted classes
probs_60_40 <- predict(model_rf_60_40, beetle_data_test_60_40, 'prob')
class_60_40 <- predict(model_rf_60_40, beetle_data_test_60_40, 'raw')
TEST_scored_60_40 <- cbind(beetle_data_test_60_40, probs_60_40, class_60_40)

# plot of probabilities
p1 <- ggplot(TEST_scored_60_40, aes(x=1:nrow(TEST_scored_60_40), y=arcticus, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of arcticus") 
p2 <- ggplot(TEST_scored_60_40, aes(x=1:nrow(TEST_scored_60_40), y=rottenbergii, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of rottenbergii") 
p3 <- ggplot(TEST_scored_60_40, aes(x=1:nrow(TEST_scored_60_40), y=fuscipes, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of fuscipes") 
p4<- ggplot(TEST_scored_60_40, aes(x=1:nrow(TEST_scored_60_40), y=subrotundus, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of subrotundus") 

ggpubr:::ggarrange(p1,p2,p3,p4,ncol=2, nrow=2)

# Plot classes
ggplot(TEST_scored_60_40, aes(x=1:nrow(TEST_scored_60_40), y=class_60_40, color=morphotype)) + 
  geom_point() +labs(color='True species', x="index", y= "Predicted species") + theme_bw()

```


## Train and test a random forest model: 25-75 split
Next, I will do training and evaluating the 25-75 split. Doing parameter tuning for the number of randomly selected predictors in each split (mtry), while keeping number of trees constant (ntree=1000). Nodesize= 1 (i.e. need at least one individual in each split). maxnode not set, meaning the tree can grow to max size. Could also tune the number of trees, but seems ok like this for this toy example.

```{r train 25-75}
# Tuning parameters: using 10-fold cross-validation with a grid search 
train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                           number=10, # number of folds
                           search = "grid", # we are performing a "grid search" for tuning
                           )
set.seed(35)
model_rf_25_75 <- train(morphotype ~ .,
                       data = beetle_data_train_25_75,
                       method = "rf", # this will use the randomForest::randomForest function
                       metric = "Accuracy", # which metric should be optimized for 
                       trControl = train_ctrl,
                        tuneLength  = 10, # the number mtry to test, 10 different ones here
                       # options to be passed to randomForest
                       ntree = 1000,
                       nodesize=1,
                       keep.forest=TRUE,
                       importance=TRUE) 
model_rf_25_75
plot(model_rf_25_75)

```

Using 2 randomly selected predictors (mtry=2) during tree splits gives best accuracy.

Check variable importance next:
```{r varimportance train 25_75}
varImpPlot(model_rf_25_75$finalModel)
```
Slightly different from the previous split, but ok. 

Next, how are the performance and confusion matrix for train and test set:
```{r performance confusionmatrix 25_75}
#Train data
p_train <- predict(model_rf_25_75, beetle_data_train_25_75)
confusionMatrix(p_train, factor(beetle_data_train_25_75$morphotype))
## 100% accurate on train data

#Test data
p_test <- predict(model_rf_25_75, beetle_data_test_25_75)
confusionMatrix(p_test, factor(beetle_data_test_25_75$morphotype))
## 3 wrong, else all correct
```

Visualize the performance/predictions
```{r 25_75 plots}
#Obtain probabilities and predicted classes
probs_25_75 <- predict(model_rf_25_75, beetle_data_test_25_75, 'prob')
class_25_75 <- predict(model_rf_25_75, beetle_data_test_25_75, 'raw')
TEST_scored_25_75 <- cbind(beetle_data_test_25_75, probs_25_75, class_25_75)

# plot of probabilities
p1 <- ggplot(TEST_scored_25_75, aes(x=1:nrow(TEST_scored_25_75), y=arcticus, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of arcticus") 
p2 <- ggplot(TEST_scored_25_75, aes(x=1:nrow(TEST_scored_25_75), y=rottenbergii, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of rottenbergii") 
p3 <- ggplot(TEST_scored_25_75, aes(x=1:nrow(TEST_scored_25_75), y=fuscipes, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of fuscipes") 
p4<- ggplot(TEST_scored_25_75, aes(x=1:nrow(TEST_scored_25_75), y=subrotundus, color=morphotype)) +
  geom_point() + labs(color='Species', x="index", y= "Predicted probability of subrotundus") 

ggpubr:::ggarrange(p1,p2,p3,p4,ncol=2, nrow=2)

# Plot classes
ggplot(TEST_scored_25_75, aes(x=1:nrow(TEST_scored_25_75), y=class_25_75, color=morphotype)) + 
  geom_point() +labs(color='True species', x="index", y= "Predicted species") + theme_bw()

```

